{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.getcwd() + '/../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "from recurrent.parameters import AllLogs\n",
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "        logging.FileHandler('plot_seeds.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set multiprocessing start method to 'spawn' to avoid JAX fork issues\n",
    "multiprocessing.set_start_method(\"spawn\", force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "download_dir = \"/scratch/downloaded_artifacts\"\n",
    "results_dir = \"/scratch/results\"\n",
    "group_name = \"fixed_weight_seed-1_cf21e420f71a4529bed03b4c48fda84c\"\n",
    "max_process_workers = 10\n",
    "\n",
    "# Ensure results directory exists\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single run's logs\n",
    "def process_run(run_result):\n",
    "    run_id = run_result[\"run_id\"]\n",
    "    artifact_dir = run_result[\"artifact_dir\"]\n",
    "    config = run_result[\"config\"]\n",
    "    \n",
    "    if run_result[\"status\"] != \"success\" or not artifact_dir or not config:\n",
    "        logger.warning(f\"Skipping run {run_id}: download failed or no config\")\n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": \"skipped\",\n",
    "            \"data\": None\n",
    "        }\n",
    "    \n",
    "    log_file = os.path.join(artifact_dir, \"logs.pkl\")\n",
    "    if not os.path.exists(log_file):\n",
    "        logger.error(f\"Logs file not found for run {run_id}\")\n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": \"no_log_file\",\n",
    "            \"data\": None\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        with open(log_file, \"rb\") as f:\n",
    "            logs = pickle.load(f)\n",
    "        \n",
    "        if not isinstance(logs, AllLogs):\n",
    "            logger.error(f\"Logs for run {run_id} is not an AllLogs instance\")\n",
    "            return {\n",
    "                \"run_id\": run_id,\n",
    "                \"status\": \"invalid_logs\",\n",
    "                \"data\": None\n",
    "            }\n",
    "        \n",
    "        # Assuming logs contains inner_learning_rate and validation_loss as arrays\n",
    "        inner_lr = np.array(logs.inner_learning_rate) if hasattr(logs, 'inner_learning_rate') else np.array([])\n",
    "        val_loss = np.array(logs.validation_loss) if hasattr(logs, 'validation_loss') else np.array([])\n",
    "        \n",
    "        if len(inner_lr) == 0 or len(val_loss) == 0:\n",
    "            logger.warning(f\"No inner_learning_rate or validation_loss data for run {run_id}\")\n",
    "            return {\n",
    "                \"run_id\": run_id,\n",
    "                \"status\": \"no_data\",\n",
    "                \"data\": None\n",
    "            }\n",
    "        \n",
    "        logger.info(f\"Processed run {run_id}\")\n",
    "        \n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": \"success\",\n",
    "            \"data\": {\n",
    "                \"config\": config,\n",
    "                \"inner_learning_rate\": inner_lr,\n",
    "                \"validation_loss\": val_loss\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing logs for run {run_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"run_id\": run_id,\n",
    "            \"status\": f\"error: {str(e)}\",\n",
    "            \"data\": None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load download results\n",
    "download_results_file = os.path.join(download_dir, f'download_results_{group_name}.pkl')\n",
    "if not os.path.exists(download_results_file):\n",
    "    logger.error(f\"Download results file not found at {download_results_file}\")\n",
    "    raise FileNotFoundError(f\"Download results file not found at {download_results_file}\")\n",
    "\n",
    "with open(download_results_file, 'rb') as f:\n",
    "    download_results = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process downloaded artifacts\n",
    "with ThreadPoolExecutor(max_workers=max_process_workers) as executor:\n",
    "    process_results = list(executor.map(process_run, download_results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect successful runs\n",
    "all_runs_data = []\n",
    "for result in process_results:\n",
    "    if result[\"status\"] == \"success\" and result[\"data\"]:\n",
    "        all_runs_data.append(result[\"data\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create seed-based plots\n",
    "def create_seed_plots(seed_type, seed_key):\n",
    "    # Group runs by seed\n",
    "    seed_groups = defaultdict(list)\n",
    "    for run in all_runs_data:\n",
    "        seed_value = run[\"config\"].get(seed_key, \"unknown\")\n",
    "        seed_groups[seed_value].append(run)\n",
    "    \n",
    "    # Sort seeds for consistent plotting\n",
    "    seeds = sorted([s for s in seed_groups.keys() if s != \"unknown\"])\n",
    "    if not seeds:\n",
    "        logger.warning(f\"No valid {seed_type} seeds found\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with n x 1 grid, each cell containing two subplots\n",
    "    n_seeds = len(seeds)\n",
    "    fig, axes = plt.subplots(n_seeds, 2, figsize=(12, 4 * n_seeds), sharex=True)\n",
    "    if n_seeds == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable for a single seed\n",
    "    \n",
    "    for idx, seed in enumerate(seeds):\n",
    "        runs = seed_groups[seed]\n",
    "        ax_lr = axes[idx][0]\n",
    "        ax_loss = axes[idx][1]\n",
    "        \n",
    "        # Plot all runs for this seed\n",
    "        for run in runs:\n",
    "            epochs = np.arange(len(run[\"inner_learning_rate\"]))\n",
    "            ax_lr.plot(epochs, run[\"inner_learning_rate\"], alpha=0.5, label=run[\"config\"].get(\"run_id\", \"unknown\"))\n",
    "            ax_loss.plot(epochs, run[\"validation_loss\"], alpha=0.5, label=run[\"config\"].get(\"run_id\", \"unknown\"))\n",
    "        \n",
    "        # Configure inner_learning_rate subplot\n",
    "        ax_lr.set_ylabel(f'Inner Learning Rate (Seed {seed})')\n",
    "        ax_lr.set_xlabel('Epoch')\n",
    "        ax_lr.grid(True)\n",
    "        if idx == 0:\n",
    "            ax_lr.set_title('Inner Learning Rate vs Epoch')\n",
    "        if len(runs) <= 10:  # Add legend only if not too many lines\n",
    "            ax_lr.legend()\n",
    "        \n",
    "        # Configure validation_loss subplot\n",
    "        ax_loss.set_ylabel(f'Validation Loss (Seed {seed})')\n",
    "        ax_loss.set_xlabel('Epoch')\n",
    "        ax_loss.grid(True)\n",
    "        if idx == 0:\n",
    "            ax_loss.set_title('Validation Loss vs Epoch')\n",
    "        if len(runs) <= 10:\n",
    "            ax_loss.legend()\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.suptitle(f'{seed_type} Seed Plots for {group_name}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    # Save to file\n",
    "    output_dir = os.path.join(results_dir, group_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f'{seed_type.lower()}_seed_plots.png')\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved {seed_type} seed plots to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots for parameter_seed\n",
    "logger.info(f\"Generating plots for parameter_seed in {group_name}\")\n",
    "create_seed_plots(\"Parameter\", \"parameter_seed\")\n",
    "\n",
    "# Generate plots for data_seed\n",
    "logger.info(f\"Generating plots for data_seed in {group_name}\")\n",
    "create_seed_plots(\"Data\", \"data_seed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
